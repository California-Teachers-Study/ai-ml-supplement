{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6ee5e3b",
   "metadata": {},
   "source": [
    "# Step 0: Connect to AWS S3 to download CTS data \n",
    "\n",
    "This is a Jupyter Notebook that demonstrates how to connect this running Sagemaker instance to the CTS data stored on AWS S3. \n",
    "\n",
    "###### By: Kingson Man, PhD, Department of Applied AI and Data Science, City of Hope\n",
    "###### Funded by NIH Grant \\#3U01CA199277-08S2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec02d5db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd  # import pandas library and alias it as pd\n",
    "import boto3  # import boto3 library for AWS S3 connection\n",
    "import os  # import os library for environment variables and file operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "905f4bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace these with your own AWS credentials ## unnecessary step while logged into AWS\n",
    "# os.environ[\"AWS_ACCESS_KEY_ID\"] = \"your_access_key_id\"\n",
    "# os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"your_secret_access_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ed1c6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code block creates a boto3 connection to AWS S3\n",
    "\n",
    "# create a boto3 session\n",
    "session = boto3.Session()\n",
    "\n",
    "# create an S3 client\n",
    "s3 = session.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e005c53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI ML Data Dictionary Current.xlsx\n",
      "data/\n",
      "data/oshpd_core_thru2020_ai_ml.csv\n",
      "data/surveydata_ai_ml.csv\n",
      "scrambled-data/\n",
      "scrambled-data/oshpd_core_thru2020_ai_ml_scrambled_5.csv\n",
      "scrambled-data/surveydata_ai_ml_scrambled_5.csv\n"
     ]
    }
   ],
   "source": [
    "# This code block lists all objects in the CTS S3 data bucket\n",
    "\n",
    "# get a list of objects in bucket\n",
    "bucket_name = \"cts-dev-sagemaker-bucket\"\n",
    "def list_objects(bucket_name):\n",
    "    response = s3.list_objects(Bucket=bucket_name)\n",
    "    for content in response.get(\"Contents\", []):\n",
    "        print(content[\"Key\"])\n",
    "\n",
    "list_objects(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "583bfd38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code block downloads a file from an S3 bucket to the local notebook instance.\n",
    "\n",
    "# choose your file\n",
    "file_key = \"data/surveydata_ai_ml.csv\"\n",
    "\n",
    "# save it as\n",
    "local_file_path = \"surveydata_ai_ml.csv\"\n",
    "\n",
    "# Define a function to download the file from S3 to your notebook instance\n",
    "def download_file(bucket_name, file_key, local_path):\n",
    "    s3.download_file(bucket_name, file_key, local_path)\n",
    "\n",
    "# Download it\n",
    "download_file(bucket_name, file_key, local_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f2791b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code block reads the surveydata_ai_ml.csv file into a pandas dataframe and displays the first 5 rows.\n",
    "\n",
    "# read the csv file into a pandas dataframe\n",
    "df = pd.read_csv('surveydata_ai_ml.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Note: The `encoding` parameter in the `pd.read_csv()` function specifies the character encoding to be used for reading the CSV file. In this case, the encoding is set to `ISO-8859-1`, which is a character encoding standard that supports a wide range of characters used in Western European languages. It is used here because the CSV file may contain characters that are not supported by the default encoding, which is `UTF-8`. By specifying the correct encoding, we can ensure that the data is read correctly into the pandas dataframe.\n",
    "\n",
    "# display the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e261cc31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The CTS data is now loaded into a pandas dataframe and may be used for further exploration and analysis.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44017e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
